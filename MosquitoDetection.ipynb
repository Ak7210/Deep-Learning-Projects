{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85240,"databundleVersionId":9622164,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:23.216942Z","iopub.execute_input":"2024-12-06T13:16:23.217843Z","iopub.status.idle":"2024-12-06T13:16:33.575067Z","shell.execute_reply.started":"2024-12-06T13:16:23.217808Z","shell.execute_reply":"2024-12-06T13:16:33.574227Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.44-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.44-py3-none-any.whl (898 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.44 ultralytics-thop-2.0.12\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport os\nimport shutil\nimport random\nimport yaml\nimport torch.nn as nn\nimport csv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:33.576787Z","iopub.execute_input":"2024-12-06T13:16:33.577074Z","iopub.status.idle":"2024-12-06T13:16:36.356556Z","shell.execute_reply.started":"2024-12-06T13:16:33.577041Z","shell.execute_reply":"2024-12-06T13:16:36.355668Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"random.seed(125)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:36.357820Z","iopub.execute_input":"2024-12-06T13:16:36.358162Z","iopub.status.idle":"2024-12-06T13:16:36.362035Z","shell.execute_reply.started":"2024-12-06T13:16:36.358136Z","shell.execute_reply":"2024-12-06T13:16:36.361188Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:36.364642Z","iopub.execute_input":"2024-12-06T13:16:36.365413Z","iopub.status.idle":"2024-12-06T13:16:37.092449Z","shell.execute_reply.started":"2024-12-06T13:16:36.365358Z","shell.execute_reply":"2024-12-06T13:16:37.091691Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Spliting the dataset into train and validation with labels","metadata":{}},{"cell_type":"code","source":"\nsource_dataset_path = \"/kaggle/input/dlp-object-detection/final_dlp_data/final_dlp_data/train/images\"\nsource_labels_path = \"/kaggle/input/dlp-object-detection/final_dlp_data/final_dlp_data/train/labels\"\ntest_data_path = \"/kaggle/input/dlp-object-detection/final_dlp_data/final_dlp_data/test/images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.093501Z","iopub.execute_input":"2024-12-06T13:16:37.093817Z","iopub.status.idle":"2024-12-06T13:16:37.097796Z","shell.execute_reply.started":"2024-12-06T13:16:37.093792Z","shell.execute_reply":"2024-12-06T13:16:37.096933Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# images file \nimages = os.listdir(source_dataset_path)\nrandom.shuffle(images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.098784Z","iopub.execute_input":"2024-12-06T13:16:37.099028Z","iopub.status.idle":"2024-12-06T13:16:37.311706Z","shell.execute_reply.started":"2024-12-06T13:16:37.099005Z","shell.execute_reply":"2024-12-06T13:16:37.310921Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Create the paths for train images and validation images\ntrain_images_path = \"dataset/train/images\"\ntrain_labels_path = \"dataset/train/labels\"\nval_images_path = \"dataset/val/images\"\nval_labels_path = \"dataset/val/labels\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.312745Z","iopub.execute_input":"2024-12-06T13:16:37.313011Z","iopub.status.idle":"2024-12-06T13:16:37.316863Z","shell.execute_reply.started":"2024-12-06T13:16:37.312985Z","shell.execute_reply":"2024-12-06T13:16:37.316094Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# create the directory if don't exist\nos.makedirs(train_images_path, exist_ok = True)\nos.makedirs(train_labels_path, exist_ok = True)\nos.makedirs(val_images_path, exist_ok = True)\nos.makedirs(val_labels_path, exist_ok = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.317838Z","iopub.execute_input":"2024-12-06T13:16:37.318063Z","iopub.status.idle":"2024-12-06T13:16:37.328243Z","shell.execute_reply.started":"2024-12-06T13:16:37.318041Z","shell.execute_reply":"2024-12-06T13:16:37.327468Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# training size = 0.85\ntrain_size = 0.9\nsplit_index = int(len(images)*train_size)\ntrain_images = images[:split_index]\nval_images =images[split_index:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.329297Z","iopub.execute_input":"2024-12-06T13:16:37.329585Z","iopub.status.idle":"2024-12-06T13:16:37.336540Z","shell.execute_reply.started":"2024-12-06T13:16:37.329543Z","shell.execute_reply":"2024-12-06T13:16:37.335790Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Copying train images and labels\nfor image in train_images:\n    #paths of destination and source\n    src_img_path = os.path.join(source_dataset_path, image)\n    dest_img_path = os.path.join(train_images_path, image)\n\n    # Check if image already exists in destination\n    if not os.path.exists(dest_img_path):\n        # Copy image to new directory\n        shutil.copy(src_img_path, dest_img_path)\n        # print(f\"image copied to the destination file for training: {image}\")\n    \n    # Copy corresponding label\n    label_name = os.path.splitext(image)[0] + '.txt' #name of label file\n    src_lab_path = os.path.join(source_labels_path, label_name)\n    dest_lab_path = os.path.join(train_labels_path, label_name)\n    \n    if (os.path.exists(src_lab_path) and not os.path.exists(dest_lab_path)):\n        shutil.copy(src_lab_path, dest_lab_path)\n        # print(f\"lable copied to the destination file for training {label_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:16:37.339071Z","iopub.execute_input":"2024-12-06T13:16:37.339353Z","iopub.status.idle":"2024-12-06T13:19:07.335031Z","shell.execute_reply.started":"2024-12-06T13:16:37.339330Z","shell.execute_reply":"2024-12-06T13:19:07.334261Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Copying train images and labels\nfor image in val_images:\n    #paths of destination and source\n    src_img_path = os.path.join(source_dataset_path, image)\n    dest_img_path = os.path.join(val_images_path, image)\n\n    # Check if image already exists in destination\n    if not os.path.exists(dest_img_path):\n        # Copy image to new directory\n        shutil.copy(src_img_path, dest_img_path)\n        # print(f\"image copied to the destination file for validation: {image}\")\n    \n    # Copy corresponding label\n    label_name = os.path.splitext(image)[0] + '.txt' #name of label file\n\n    src_lab_path = os.path.join(source_labels_path, label_name) \n    dest_lab_path = os.path.join(val_labels_path, label_name)\n    \n    if (os.path.exists(src_lab_path) and not os.path.exists(dest_lab_path)):\n        shutil.copy(src_lab_path, dest_lab_path)\n        # print(f\"label copied to the destination file for validation: {label_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:19:07.336211Z","iopub.execute_input":"2024-12-06T13:19:07.336556Z","iopub.status.idle":"2024-12-06T13:19:22.692236Z","shell.execute_reply.started":"2024-12-06T13:19:07.336515Z","shell.execute_reply":"2024-12-06T13:19:22.691518Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# writing a data.yaml\ndata_yaml = \"\"\"\ntrain: /kaggle/working/dataset/train/images\nval: /kaggle/working/dataset/val/images\n\nnc: 6\nnames: [\"aegypti\", \"albopictus\", \"anopheles\", \"culex\", \"culiseta\", \"japonicus/koreicus\"]\n\"\"\"\n\n# Save dataset.yaml\nwith open(\"dataset/data.yaml\", \"w\") as f:\n    f.write(data_yaml)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:19:22.693166Z","iopub.execute_input":"2024-12-06T13:19:22.693429Z","iopub.status.idle":"2024-12-06T13:19:22.698306Z","shell.execute_reply.started":"2024-12-06T13:19:22.693400Z","shell.execute_reply":"2024-12-06T13:19:22.697355Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = YOLO(\"yolov5x6u.pt\")\nmodel.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:19:22.699279Z","iopub.execute_input":"2024-12-06T13:19:22.699555Z","iopub.status.idle":"2024-12-06T13:19:27.261318Z","shell.execute_reply.started":"2024-12-06T13:19:22.699531Z","shell.execute_reply":"2024-12-06T13:19:27.260510Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5x6u.pt to 'yolov5x6u.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 297M/297M [00:00<00:00, 350MB/s] \n","output_type":"stream"},{"name":"stdout","text":"YOLOv5x6u summary: 638 layers, 155,544,432 parameters, 0 gradients, 251.7 GFLOPs\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(638, 155544432, 0, 251.654336)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"training_results = model.train(\n    data = '/kaggle/working/dataset/data.yaml',\n    epochs = 15,\n    batch = 16,\n    imgsz = 640, #default\n    device = [0,1],\n    workers = 4,\n    project = \"runs/output\", #path where I want to save the model output\n    name = 'mosquito_detection',\n    optimizer = 'SGD',\n    momentum = 0.935,\n    seed = 111,\n    cos_lr = True,\n    close_mosaic = 0,\n    lr0 = 0.001,\n    lrf = 0.2,\n    # dropout = 0.2,\n    plots = True,\n    pretrained = False,\n    weight_decay = 0.0004,\n    #augmentation for the training \n    hsv_h = 0.015,\n    hsv_s = 0.5,\n    hsv_v = 0.3,\n    degrees = 0.4,\n    translate = 0.1,\n    scale = 0.5,\n    # bgr=0.05,\n    shear = 0.1,\n    mosaic = 1,\n    erasing = 0, \n    mixup = 0.2,\n    # dropout= 0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:19:27.262626Z","iopub.execute_input":"2024-12-06T13:19:27.262993Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.44 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n                                                 CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5x6u.pt, data=/kaggle/working/dataset/data.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=4, project=runs/output, name=mosquito_detection, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=111, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.2, momentum=0.935, weight_decay=0.0004, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.5, hsv_v=0.3, degrees=0.4, translate=0.1, scale=0.5, shear=0.1, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/output/mosquito_detection\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=6\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      8800  ultralytics.nn.modules.conv.Conv             [3, 80, 6, 2, 2]              \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  4    309120  ultralytics.nn.modules.block.C3              [160, 160, 4]                 \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  8   2259200  ultralytics.nn.modules.block.C3              [320, 320, 8]                 \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1 12  13125120  ultralytics.nn.modules.block.C3              [640, 640, 12]                \n  7                  -1  1   5531520  ultralytics.nn.modules.conv.Conv             [640, 960, 3, 2]              \n  8                  -1  4  11070720  ultralytics.nn.modules.block.C3              [960, 960, 4]                 \n  9                  -1  1  11061760  ultralytics.nn.modules.conv.Conv             [960, 1280, 3, 2]             \n 10                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4]               \n 11                  -1  1   4099840  ultralytics.nn.modules.block.SPPF            [1280, 1280, 5]               \n 12                  -1  1   1230720  ultralytics.nn.modules.conv.Conv             [1280, 960, 1, 1]             \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  4  11992320  ultralytics.nn.modules.block.C3              [1920, 960, 4, False]         \n 16                  -1  1    615680  ultralytics.nn.modules.conv.Conv             [960, 640, 1, 1]              \n 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 18             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  4   5332480  ultralytics.nn.modules.block.C3              [1280, 640, 4, False]         \n 20                  -1  1    205440  ultralytics.nn.modules.conv.Conv             [640, 320, 1, 1]              \n 21                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 22             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 23                  -1  4   1335040  ultralytics.nn.modules.block.C3              [640, 320, 4, False]          \n 24                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 25            [-1, 20]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 26                  -1  4   4922880  ultralytics.nn.modules.block.C3              [640, 640, 4, False]          \n 27                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 28            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 29                  -1  4  11377920  ultralytics.nn.modules.block.C3              [1280, 960, 4, False]         \n 30                  -1  1   8296320  ultralytics.nn.modules.conv.Conv             [960, 960, 3, 2]              \n 31            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 32                  -1  4  20495360  ultralytics.nn.modules.block.C3              [1920, 1280, 4, False]        \n 33    [23, 26, 29, 32]  1  15471656  ultralytics.nn.modules.head.Detect           [6, [320, 640, 960, 1280]]    \nYOLOv5x6u summary: 638 layers, 155,449,416 parameters, 155,449,400 gradients, 251.3 GFLOPs\n\nTransferred 1059/1067 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 46133 /root/.config/Ultralytics/DDP/_temp_rbnjl5i6138608846868480.py\nUltralytics 8.3.44 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n                                                 CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/output/mosquito_detection', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=6\nTransferred 1059/1067 items from pretrained weights\nFreezing layer 'model.33.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 70.4MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train/labels... 3524 images, 0 backgrounds, 1 corrupt:  52%|█████▏    | 3524/6750 [00:03<00:03, 1053.04it/s]/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train/labels... 6750 images, 0 backgrounds, 1 corrupt: 100%|██████████| 6750/6750 [00:06<00:00, 1078.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/dataset/train/images/120b30b0-c7db-4f0a-bead-a30424a65453.jpeg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0068]\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val/labels... 750 images, 0 backgrounds, 0 corrupt: 100%|██████████| 750/750 [00:00<00:00, 1181.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/val/labels.cache\nPlotting labels to runs/output/mosquito_detection/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.935) with parameter groups 175 weight(decay=0.0), 184 weight(decay=0.0004), 183 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/output/mosquito_detection\u001b[0m\nStarting training for 15 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/15      11.3G      1.386      2.633      1.588         22        640: 100%|██████████| 422/422 [06:00<00:00,  1.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:23<00:00,  2.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        750        750      0.583      0.318        0.3      0.214\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/15      10.5G      1.105      1.424      1.353         14        640: 100%|██████████| 422/422 [05:52<00:00,  1.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:23<00:00,  1.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        750        750      0.685      0.474      0.409      0.303\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/15      10.4G      1.101      1.151       1.35         16        640: 100%|██████████| 422/422 [05:47<00:00,  1.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:22<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        750        750      0.681      0.474      0.435      0.326\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/15      10.4G      1.078      1.055      1.323         13        640: 100%|██████████| 422/422 [05:46<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:23<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        750        750      0.758      0.482      0.472      0.358\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/15      10.4G      1.068     0.9928      1.311         22        640: 100%|██████████| 422/422 [05:46<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 47/47 [00:22<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        750        750      0.745      0.445      0.468      0.365\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/15      10.4G      1.058     0.9333      1.323         17        640:  28%|██▊       | 120/422 [01:38<04:08,  1.22it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"validation_result = model.val()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_result.box.maps","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prediction = model.predict(source=test_data_path,\n                           conf=0.4, \n                           save=True,\n                           batch = 16, \n                           imgsz = 640,\n                           device = 'cuda:0',\n                           iou = 0.6,\n                           save_txt = True,\n                           save_conf = True,                           \n                          )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_missing_labels(test_path, label_path):\n    \"\"\"\n    Identifies images in the test path without corresponding labels in the label path.\n    \"\"\"\n    test_images_name = os.listdir(test_path)\n    label_images_name = os.listdir(label_path)\n\n    test_name = {i.strip().split(\".\")[0] for i in test_images_name}\n    lab_name = {i.strip().split(\".\")[0] for i in label_images_name}\n\n    missing_labels = test_name - lab_name\n    return list(missing_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parse_prediction_file(file_path, label_mapping):\n    \"\"\"\n    Parses a single prediction file to extract the best prediction based on confidence score.\n    \"\"\"\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n\n        if not lines:\n            return None\n    \n        highest_confidence = -1\n        best_prediction = None\n    \n        for line in lines:\n            values = line.strip().split()  # Split line into components\n            label = label_mapping[int(values[0])]\n            xcenter = float(values[1])\n            ycenter = float(values[2])\n            bbx_width = float(values[3])\n            bbx_height = float(values[4])\n            conf = float(values[5])\n    \n            if conf > highest_confidence:\n                highest_confidence = conf\n                best_prediction = {\n                    'LabelName': label,\n                    'Conf': conf,\n                    'xcenter': xcenter,\n                    'ycenter': ycenter,\n                    'bbx_width': bbx_width,\n                    'bbx_height': bbx_height\n                }\n        return best_prediction\n    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_predictions(predictions_path, label_mapping):\n    \"\"\"\n    Generates predictions from label files in the predictions path.\n    \"\"\"\n    predicted_labels = os.listdir(predictions_path)\n    results = []\n\n    for label_file in predicted_labels:\n        predicted_image_name = label_file.split(\".\")[0]\n        file_path = os.path.join(predictions_path, label_file)\n        best_prediction = parse_prediction_file(file_path, label_mapping)\n\n        if best_prediction:\n            best_prediction['ImageID'] = predicted_image_name\n            results.append(best_prediction)\n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def handle_missing_images(missing_images, label_mapping):\n    \"\"\"\n    Handles missing images by assigning random predictions.\n    \"\"\"\n    return [\n        {\n            'ImageID': image_id,\n            'LabelName': random.choice(list(label_mapping.values())),\n            'Conf': random.uniform(0.5,1),\n            'xcenter': random.uniform(0.1,1),\n            'ycenter': random.uniform(0.1,1),\n            'bbx_width': random.uniform(0.1,1),\n            'bbx_height': random.uniform(0.1,1),\n        }\n        for image_id in missing_images\n    ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_to_csv(output_file, data):\n    \"\"\"\n    Saves the data to a CSV file with incremental IDs.\n    \"\"\"\n    with open(output_file, 'w', newline='') as csvfile:\n        fieldnames = ['id', 'ImageID', 'LabelName', 'Conf', 'xcenter', 'ycenter', 'bbx_width', 'bbx_height']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        # Write the header\n        writer.writeheader()\n\n        # Write the data\n        for idx, row in enumerate(data):\n            row_with_id = {'id': idx, **row}\n            writer.writerow(row_with_id)\n\n    print(f\"CSV file saved as {output_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_mapping = {\n    0: \"aegypti\", 1: \"albopictus\", 2: \"anopheles\",\n    3: \"culex\", 4: \"culiseta\", 5: \"japonicus/koreicus\"\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_label_path = \"/kaggle/working/runs/output/mosquito_detection3/labels\"\n\npredicted_labels = os.listdir(predictions_label_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_images = get_missing_labels(test_data_path, predictions_label_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(missing_images))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = generate_predictions(predictions_label_path, label_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_predictions = handle_missing_images(missing_images, label_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_file = 'submission_SGD_3.csv'\n\n# Combine predictions\nall_predictions = predictions + missing_predictions\n\n# Step 4: Save results to CSV by using the function\nsave_to_csv(output_file, all_predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}